import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from sentence_transformers import SentenceTransformer
import json

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø²Ù…Ø§Øª", layout="wide")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù…ÙˆØ¯ÙŠÙ„
@st.cache_data(ttl=600)
def load_data():
    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    creds_dict = json.loads(st.secrets["GOOGLE_CREDENTIALS"])
    creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
    client = gspread.authorize(creds)
    sheet = client.open_by_key(st.secrets["SHEET_ID"])
    data_sheet = sheet.sheet1

    data = data_sheet.get_all_records()
    df = pd.DataFrame(data)

    password_cell = data_sheet.cell(1, 5).value

    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
    descriptions = df['ÙˆØµÙ Ø§Ù„Ø­Ø§Ù„Ø© Ø£Ùˆ Ø§Ù„Ø­Ø¯Ø«'].fillna("").astype(str).tolist()
    embeddings = model.encode(descriptions, convert_to_tensor=True)

    return df, model, embeddings, password_cell

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.title("ğŸ› ï¸ Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø²Ù…Ø§Øª")

# Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
user_password = st.text_input("Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:", type="password")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
df, model, embeddings, PASSWORD = load_data()

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
if user_password == PASSWORD:
    st.success("ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± âœ…")
    st.subheader("ğŸ“‹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©")
    st.dataframe(df, use_container_width=True)

    # Ø¥Ø¯Ø®Ø§Ù„ ÙˆØµÙ Ø§Ù„Ø­Ø§Ù„Ø©
    query = st.text_area("Ø£Ø¯Ø®Ù„ ÙˆØµÙ Ø§Ù„Ø­Ø§Ù„Ø© Ø£Ùˆ Ø§Ù„Ø­Ø¯Ø«:", max_chars=300)

    if query:
        query_embedding = model.encode([query], convert_to_tensor=True)
        from torch.nn.functional import cosine_similarity
        scores = cosine_similarity(query_embedding, embeddings)[0]
        top_idx = scores.argmax().item()
        st.markdown("### ğŸ¯ Ø£Ù‚Ø±Ø¨ Ø­Ø§Ù„Ø© Ù…Ø´Ø§Ø¨Ù‡Ø©:")
        st.write(df.iloc[top_idx])
else:
    st.warning("ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø© Ø£Ùˆ Ù„Ù… ØªÙØ¯Ø®Ù„ Ø¨Ø¹Ø¯.")
