import streamlit as st
import gspread
from google.oauth2.service_account import Credentials
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import torch
import json, os, re

# ---------- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ----------
SHEET_ID = "11BWnvPjcRZwnGhynCCyYCc7MGfHJlSyJCqwHI6z4KJI"

# ---------- ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ----------
def normalize_arabic(text):
    text = re.sub(r"[\u0617-\u061A\u064B-\u0652]", "", text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    text = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", text)  # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ù„Ù
    text = re.sub(r"Ù‰", "ÙŠ", text)        # ØªÙˆØ­ÙŠØ¯ Ø§Ù„ÙŠØ§Ø¡
    return text.strip()

# ---------- Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Google Sheet ----------
@st.cache_data(ttl=600)
def load_data():
    try:
        scopes = ["https://www.googleapis.com/auth/spreadsheets"]
        service_account_info = json.loads(os.getenv("GCP_SERVICE_ACCOUNT"))
        creds = Credentials.from_service_account_info(service_account_info, scopes=scopes)
        client = gspread.authorize(creds)
        sheet = client.open_by_key(SHEET_ID)
        data_sheet = sheet.sheet1

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data = data_sheet.get_all_records()
        df = pd.DataFrame(data)

        # ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ù…Ù† E1
        password_cell = data_sheet.cell(1, 5).value  # E1

        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (LaBSE)
        model = SentenceTransformer("sentence-transformers/LaBSE")

        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
        descriptions = [normalize_arabic(str(d)) for d in df['ÙˆØµÙ Ø§Ù„Ø­Ø§Ù„Ø© Ø£Ùˆ Ø§Ù„Ø­Ø¯Ø«'].fillna("")]
        embeddings = model.encode(descriptions, convert_to_tensor=True)

        return df, model, embeddings, password_cell
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¬ÙˆØ¬Ù„ Ø´ÙŠØª: {e}")
        st.stop()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
df, model, embeddings, PASSWORD = load_data()

# ---------- ÙˆØ§Ø¬Ù‡Ø© ----------
st.set_page_config(page_title="âš¡ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ÙƒÙˆØ§Ø±Ø« ÙˆØ§Ù„Ø£Ø²Ù…Ø§Øª", layout="centered", initial_sidebar_state="collapsed")

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.markdown("<h2>Ø§Ø¯Ø®Ù„ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø³Ø±ÙŠ</h2>", unsafe_allow_html=True)
    password = st.text_input("Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø³Ø±ÙŠ", type="password")
    if st.button("Ø¯Ø®ÙˆÙ„") or st.session_state.get("enter_pressed", False):
        if password == PASSWORD:
            st.session_state.authenticated = True
            st.session_state.enter_pressed = False
            st.rerun()
        else:
            st.error("âŒ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø³Ø±ÙŠ ØºÙŠØ± ØµØ­ÙŠØ­")
else:
    st.markdown("<h2>âš¡ Ø¯Ø§Ø¦Ø±Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ÙƒÙˆØ§Ø±Ø« ÙˆØ§Ù„Ø£Ø²Ù…Ø§Øª Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ©</h2>", unsafe_allow_html=True)

    # Ù…Ø±Ø¨Ø¹ Ø§Ù„Ø¨Ø­Ø« Ù…Ø¹ Ø§Ù„Ø±Ù…ÙˆØ²
    query = st.text_input("Ø§Ø¨Ø­Ø« Ù‡Ù†Ø§:", placeholder="âš¡ ğŸ”¥ ğŸš” ğŸš— ğŸ›¢ï¸ ğŸ’§")

    # Ø¹Ø±Ø¶ ØªÙ„Ù…ÙŠØ­ Ø¨Ø§Ù„Ø±Ù…ÙˆØ²
    st.info("âš¡ Ù…Ø´Ø§ÙƒÙ„ ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©  |  ğŸ”¥ Ø­Ø±Ø§Ø¦Ù‚  |  ğŸš” Ø£Ù…Ù† ØµÙ†Ø§Ø¹ÙŠ  |  ğŸš— Ø­ÙˆØ§Ø¯Ø« Ø³ÙŠØ§Ø±Ø§Øª  |  ğŸ›¢ï¸ Ø¨Ø±Ù…ÙŠÙ„ Ø²ÙŠØª  |  ğŸ’§ Ø§Ù†Ø³ÙƒØ§Ø¨")

    if query:
        query_norm = normalize_arabic(query)
        words = query_norm.lower().split()
        literal_results = []
        synonym_results = []

        # --- 1) Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­Ø±ÙÙŠ Ù…Ù† Ø§Ù„ÙˆØµÙ ---
        for idx, row in df.iterrows():
            text = normalize_arabic(str(row['ÙˆØµÙ Ø§Ù„Ø­Ø§Ù„Ø© Ø£Ùˆ Ø§Ù„Ø­Ø¯Ø«']).lower())
            if all(word in text for word in words):
                literal_results.append(row)

        # --- 2) Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­Ø±ÙÙŠ Ù…Ù† Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª ---
        if not literal_results:  # ÙÙ‚Ø· Ù„Ùˆ Ù…Ø§ÙÙŠÙ‡ Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Ø§Ù„ÙˆØµÙ
            for idx, row in df.iterrows():
                synonyms = normalize_arabic(str(row.get('Ù…Ø±Ø§Ø¯ÙØ§Øª Ù„Ù„ÙˆØµÙ', '')).lower()).split(',')
                synonyms = [s.strip() for s in synonyms if s.strip()]
                if any(word in synonyms for word in words):
                    synonym_results.append(row)

        # --- Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ---
        if literal_results:
            st.subheader("ğŸ” Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­Ø±ÙÙŠ (Ù…Ù† Ø§Ù„ÙˆØµÙ):")
            for r in literal_results[:3]:
                st.markdown(
                    f"""
                    <div style='background-color:#1f1f1f;color:white;padding:10px;border-radius:5px;direction:rtl;text-align:right;font-size:18px;'>
                        <b>Ø§Ù„ÙˆØµÙ:</b> {r['ÙˆØµÙ Ø§Ù„Ø­Ø§Ù„Ø© Ø£Ùˆ Ø§Ù„Ø­Ø¯Ø«']}<br>
                        <b>Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡:</b>
                        <span style='background-color:#ff6600;color:#0a1e3f;padding:4px 8px;border-radius:5px;'>
                        {r['Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡']}
                        </span>
                    </div><br>
                    """, unsafe_allow_html=True)

        elif synonym_results:
            st.subheader("ğŸ“Œ Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª:")
            for r in synonym_results[:3]:
                st.markdown(
                    f"""
                    <div style='background-color:#333;color:white;padding:10px;border-radius:5px;direction:rtl;text-align:right;font-size:18px;'>
                        <b>Ø§Ù„ÙˆØµÙ:</b> {r['ÙˆØµÙ Ø§Ù„Ø­Ø§Ù„Ø© Ø£Ùˆ Ø§Ù„Ø­Ø¯Ø«']}<br>
                        <b>Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡:</b>
                        <span style='background-color:#ff6600;color:#0a1e3f;padding:4px 8px;border-radius:5px;'>
                        {r['Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡']}
                        </span>
                    </div><br>
                    """, unsafe_allow_html=True)

        else:
            # --- 3) Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ ---
            st.warning("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø­Ø±ÙÙŠØ© .. Ø¬Ø±Ø¨ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ ğŸ‘‡")

            if st.button("ğŸ¤– Ø¬Ø±Ø¨ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ"):
                query_embedding = model.encode(query_norm, convert_to_tensor=True)
                cosine_scores = util.pytorch_cos_sim(query_embedding, embeddings)[0]
                top_results = torch.topk(cosine_scores, k=3)

                st.subheader("ğŸ” Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ:")
                for score, idx in zip(top_results[0], top_results[1]):
                    r = df.iloc[idx.item()]
                    st.markdown(
                        f"""
                        <div style='background-color:#444;color:white;padding:10px;border-radius:5px;direction:rtl;text-align:right;font-size:18px;'>
                            <b>Ø§Ù„ÙˆØµÙ:</b> {r['ÙˆØµÙ Ø§Ù„Ø­Ø§Ù„Ø© Ø£Ùˆ Ø§Ù„Ø­Ø¯Ø«']}<br>
                            <b>Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡:</b>
                            <span style='background-color:#ff6600;color:#0a1e3f;padding:4px 8px;border-radius:5px;'>
                            {r['Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡']}
                            </span><br>
                            <span style='font-size:14px;color:orange;'>Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {score:.2f}</span>
                        </div><br>
                        """, unsafe_allow_html=True)

    if st.button("ğŸ”’ ØªØ³Ø¬ÙŠÙ„ Ø®Ø±ÙˆØ¬"):
        st.session_state.authenticated = False
        st.rerun()
